% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/varImpact-all-three.R, R/varImpact.R
\name{varImpact}
\alias{varImpact}
\title{Variable Impact Estimation
\code{varImpact} returns variable importance statistics ordered
by statistical significance}
\usage{
varImpact(Y, data, V = 2, Q.library = c("SL.gam", "SL.glmnet", "SL.mean"),
  g.library = c("SL.stepAIC"), family = "binomial", minYs = 15,
  minCell = 0, ncov = 10, corthres = 0.8, impute = "median",
  miss.cut = 0.5, verbose = F, parallel = T)

varImpact(Y, data, V = 2, Q.library = c("SL.gam", "SL.glmnet", "SL.mean"),
  g.library = c("SL.stepAIC"), family = "binomial", minYs = 15,
  minCell = 0, ncov = 10, corthres = 0.8, impute = "median",
  miss.cut = 0.5, verbose = F, parallel = T)
}
\arguments{
\item{Y}{outcome of interest (numeric vector)}

\item{data}{data frame of predictor variables of interest for
which function returns VIM's. (possibly a matrix?)}

\item{V}{Number of cross-validation folds.}

\item{Q.library}{library used by SuperLearner for model of outcome
versus predictors}

\item{g.library}{library used by SuperLearner for model of
predictor variable of interest versus other predictors}

\item{family}{family ('binomial' or 'gaussian')}

\item{minYs}{mininum # of obs with event  - if it is < minYs, skip VIM}

\item{minCell}{is the cut-off for including a category of
A in analysis, and  presents the minumum of cells in a 2x2 table of the indicator of
that level versus outcome, separately by training and validation
sample}

\item{ncov}{minimum number of covariates to include as adjustment variables (must
be less than # of basis functions of adjustment matrix)}

\item{impute}{Type of missing value imputation to conduct. One of: "zero", "median" (default), "knn".}

\item{miss.cut}{eliminates explanatory (X) variables with proportion
of missing obs > cut.off}

\item{verbose}{Boolean - if TRUE the method will display more detailed output.}

\item{parallel}{Use parallel processing if a backend is registered.}

\item{cothres}{cut-off correlation with explanatory
variable for inclusion of an adjustment variables}

\item{dirout}{directory to write output}

\item{outname}{prefix name for files}

\item{Y}{outcome of interest (numeric vector)}

\item{data}{data frame of predictor variables of interest for
which function returns VIM's. (possibly a matrix?)}

\item{V}{Number of cross-validation folds.}

\item{Q.library}{library used by SuperLearner for model of outcome
versus predictors}

\item{g.library}{library used by SuperLearner for model of
predictor variable of interest versus other predictors}

\item{family}{family ('binomial' or 'gaussian')}

\item{minYs}{mininum # of obs with event  - if it is < minYs, skip VIM}

\item{minCell}{is the cut-off for including a category of
A in analysis, and  presents the minumum of cells in a 2x2 table of the indicator of
that level versus outcome, separately by training and validation
sample}

\item{ncov}{minimum number of covariates to include as adjustment variables (must
be less than # of basis functions of adjustment matrix)}

\item{cothres}{cut-off correlation with explanatory
variable for inclusion of an adjustment variables}

\item{miss.cut}{eliminates explanatory (X) variables with proportion
of missing obs > cut.off}

\item{verbose}{Boolean - if TRUE the method will display more detailed output.}
}
\value{
TBD.
}
\description{
Returns ordered estimates of variable importance measures using
a combination of data-adaptive target parameter estimation, and
targeted maximum likelihood estimation (TMLE).

\code{varImpact} returns variable importance statistics ordered
by statistical significance using
a combination of data-adaptive target parameter estimation, and
targeted maximum likelihood estimation (TMLE).
}
\details{
The function performs the following functions.
 \enumerate{
 \item Drops variables missing > miss.cut of time (tuneable).
 \item Separate out covariates into factors and continuous (ordered).
 \item Drops variables for which their distribution is uneven  - e.g., all 1 value (tuneable)
 separately for factors and numeric variables (ADD MORE DETAIL HERE)
 \item Changes all factors to remove spaces (used for naming dummies later)
 \item Changes variable names to remove spaces
 \item Makes dummy variable basis for factors, including naming dummies
 to be traceable to original factor variable laters
 \item Makes new ordered variable of integers mapped to intervals defined by deciles for the ordered numeric variables (automatically makes)
 fewer categories if original variable has < 10 values.
 \item Creates associated list of number of unique values and the list of them
 for each variable for use in variable importance part.
 \item Makes missing covariate basis for both factors and ordered variables
 \item For each variable, after assigning it as A, uses
 optimal histogram function to combine values using the
 distribution of A | Y=1 to avoid very small cell sizes in
 distribution of Y vs. A (tuneable) (ADD DETAIL)
 \item Uses HOPACH to cluster variables associated confounder/missingness basis for W,
 that uses specified minimum number of adjustment variables.
 \item Finds min and max estimate of E(Ya) w.r.t. a. after looping through
 all values of A* (after processed by histogram)
 \item Returns estimate of E(Ya(max)-Ya(min)) with SE
 \item Returns 3 latex table files:
 \itemize{
   \item AllReslts.tex - the file with cross-validated average variable impacts ordered by statistical significance.
   \item byV.tex - the comparison levels used within each validation sample.  Either integer ordering of factors or short-hand for percentile cut-off (0-1 is the 10th percentile, 10+ is the 100th percentile)
   \item ConsistReslts.tex - the ``consistent'' significant results, meaning those with consistent categories chosen as comparison groups among factors and consistent ordering for numeric variables.
}
 \item Things to do include making options to avoid errors include putting
minimum cell size on validation sample of A vs. Y
and implementing CV-TMLE (minCell), making examples, putting authors
and references and see also's.  Allow reporting of results that
randomly do not have estimates for some of validation samples.
}

The function performs the following functions.
 \enumerate{
 \item Drops variables missing > miss.cut of time (tuneable).
 \item Separate out covariates into factors and continuous (ordered).
 \item Drops variables for which their distribution is uneven  - e.g., all 1 value (tuneable)
 separately for factors and numeric variables (ADD MORE DETAIL HERE)
 \item Changes all factors to remove spaces (used for naming dummies later)
 \item Changes variable names to remove spaces
 \item Makes dummy variable basis for factors, including naming dummies
 to be traceable to original factor variable laters
 \item Makes new ordered variable of integers mapped to intervals defined by deciles for the ordered numeric variables (automatically makes)
 fewer categories if original variable has < 10 values.
 \item Creates associated list of number of unique values and the list of them
 for each variable for use in variable importance part.
 \item Makes missing covariate basis for both factors and ordered variables
 \item For each variable, after assigning it as A, uses
 optimal histogram function to combine values using the
 distribution of A | Y=1 to avoid very small cell sizes in
 distribution of Y vs. A (tuneable) (ADD DETAIL)
 \item Uses HOPACH to cluster variables associated confounder/missingness basis for W,
 that uses specified minimum number of adjustment variables.
 \item Finds min and max estimate of E(Ya) w.r.t. a. after looping through
 all values of A* (after processed by histogram)
 \item Returns estimate of E(Ya(max)-Ya(min)) with SE
 \item Things to do include implementing CV-TMLE, making examples, putting authors
and references and see also's.  Allow reporting of results that
randomly do not have estimates for some of validation samples.
}
}
\examples{
# Multicore example.
library(doMC)
registerDoMC()
vim = varImpact(Y = Y, data = X)

}

